<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Music Visualization with Three.js</title>
    <style>
html, body {
  margin: 0;
  padding: 0;
  overflow: hidden; /* Prevent scrollbars */
  height: 100%; /* Full height */
  width: 100%; /* Full width */
}

#youtube-player {
  position: fixed; /* Fixed position */
  top: 0;
  left: 0;
  width: 100vw; /* Viewport width */
  height: 100vh; /* Viewport height */
  z-index: -1; /* Behind other content */
}

#threejs-container {
  position: relative;
  width: 100%;
  height: 100%;
  z-index: 1; /* Above the video background */
}

#button {
position: fixed; 
top: 40%;
left: 45%;
width: 10%;
height: 5%;
box-shadow: 2px 2px 10px 0px black;
z-index: 11;
}
.button {
position: relative; 
width: 48%;
background-color: white;
color: black;

}

</style>
  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>

<script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/objects/Reflector.js"></script>
<script src="https://www.youtube.com/iframe_api"></script>



</head>
<body>

<div id="threejs-container"></div>



<div id="youtube-player"></div>

<div id="button">
<button class="button" id="play" onClick="playPause()"> > </button>
<button class="button" id="next" onClick="next()"> >> </button>
<input type="range" id="volume" onChange="volume()" max="100" min="0" value="50">
</div>
    <script>
class AudioVisualizerGrid {
  constructor(scene, analyser, colors, plane) {
    this.colors = [colors];
    this.scene = scene;
    this.analyser = analyser;
    this.boxes = [];
    this.initGrid();
  }
initGrid() {
  const gridWidth = 10;  
  const gridDepth = 10;
  const boxSize = 15;
  const spacing = 250;
  const xOffset = -(gridWidth - 1) * spacing / 1.5;
  const zOffset = -(gridDepth - 1) * spacing / 1.5;

  for (let i = 0; i < gridWidth; i++) {
    for (let j = 0; j < gridDepth; j++) {
      const geometry = new THREE.BoxGeometry(boxSize, 0.1, boxSize);
      geometry.translate(boxSize / 2, 0.05, boxSize / 2);
      const material = new THREE.MeshStandardMaterial({ color: 0x00ff00 })
      material.metalness = 0.9;
      material.roughness = 0;
      const box = new THREE.Mesh(geometry, material);
      box.castShadow = true;
      box.receiveShadow = true;
      box.position.set(i * spacing + xOffset, -200, j * spacing + zOffset);
      this.scene.add(box);
      this.boxes.push(box);
    }
  }
}


  updateGrid(dataArray, volume) {
    const baseHeight = volume * (10 - 0.1) + 0.1;
    for (let i = 0; i < this.boxes.length; i++) {
      const box = this.boxes[i];
      const frequencyValue = dataArray[i];
      const scaleValue = frequencyValue / 255 * 150 * baseHeight * baseHeight;
      box.scale.y = scaleValue / 3;
     
       const colorIndex = Math.floor((frequencyValue / 255) * (colors.length));
  box.material.color = colors[colorIndex];
  box.material.emissive = colors[colorIndex];

    }
  }
}

        // Create 
 const scene = new THREE.Scene();
 const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
         camera.position.x = 0;
	camera.position.y = 15;
	camera.position.z = 359;
	camera.rotation.y = 0;
	camera.rotation.x = 0;
	camera.rotation.z = -0;
var renderer = new THREE.WebGLRenderer({ alpha: true });
renderer.setSize(window.innerWidth, window.innerHeight);



var isPlaying = true; 
const colors = [
  new THREE.Color(0xff6fde),
  new THREE.Color(0xfe4db8),
  new THREE.Color(0x198cff), 
  new THREE.Color(0x87CEEB), 
  new THREE.Color(0x800080), 
];
const light = new THREE.DirectionalLight(0xffffff, 1);
light.position.set(5, 5, 5);
light.castShadow = true;
light.shadow.camera.near = 0.1;
light.shadow.camera.far = 50;
scene.add(light);
const floorWidth = 2000; // Arbitrary large value
const floorHeight = 2000; // Arbitrary large value
const planeGeometry = new THREE.PlaneGeometry(floorWidth, floorHeight);
var textureLoader = new THREE.TextureLoader();
textureLoader.load('https://upload.wikimedia.org/wikipedia/en/c/cd/Taylor_Swift_-_Lover.png', function(texture) {

    
   
    var pmaterial = new THREE.MeshBasicMaterial({ map: texture });

    
var plane1 = new THREE.Mesh(planeGeometry, pmaterial);
plane1.rotation.x = Math.PI / 2;

plane1.rotation.y = -Math.PI;
plane1.rotation.z = 0;
plane1.position.y = -200 //Adjust as necessary
plane1.position.x = 0;
plane1.position.z = 0;
plane1.receiveShadow = true;
plane1.material.color = new THREE.Color(0xffffff); // White color for reflector material
plane1.material.opacity = 0.7; // Adjust for faintness of reflection
plane.material.opacity = 0.5;
plane1.material.transparent = true; // Necessary for opacity to work

scene.add(plane1);
plane.parent = plane1;
});
var geometry = new THREE.PlaneGeometry(floorWidth, floorHeight);
var plane = new THREE.Reflector(geometry, {
  clipBias: 0.003,
  textureWidth: window.innerWidth * window.devicePixelRatio,
  textureHeight: window.innerHeight * window.devicePixelRatio,
  // Color of the reflector
	
});

const ambientLight = new THREE.AmbientLight(0xffffff, 0.5); // soft white light
scene.add(ambientLight);
const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
directionalLight.position.set(5, 10, 7.5); // Position the light
directionalLight.castShadow = true; // Enable shadows
scene.add(directionalLight);
const hemiLight = new THREE.HemisphereLight(0xffffff, 0x444444, 1);
hemiLight.position.set(0, 20, 0);
scene.add(hemiLight);


plane.rotation.x = 0; 
plane.rotation.y = 0;
plane.rotation.z = -0;

plane.position.x = 0;
plane.position.z = 0;
plane.position.y = 0; // Adjust as necessary
plane.receiveShadow = true;
// Assuming 'plane' is your Reflector object
// Adjust the reflectivity property if available or control the color intensity

// Rerender the scene
renderer.render(scene, camera);
scene.add(plane);

// Assuming you have the following in your scene:
// - THREE.Scene named 'scene'
// - camera
// - renderer

// Create a video element
const video = document.createElement('video');
video.src = '1.mp4'; // Set the path to your video file
video.load();

video.loop = true;

const videoTexture = new THREE.VideoTexture(video);
videoTexture.minFilter = THREE.LinearFilter;
videoTexture.magFilter = THREE.LinearFilter;
videoTexture.format = THREE.RGBFormat;

// This function will resize the video plane to match the camera's aspect
function resizeVideoMeshToCoverCameraView(camera, videoMesh) {
    const cameraViewHeight = 2 * Math.tan(THREE.MathUtils.degToRad(camera.fov) / 2) * camera.position.z;
    const cameraViewWidth = cameraViewHeight * camera.aspect;

    videoMesh.scale.x = cameraViewWidth * 2;
    videoMesh.scale.y = cameraViewHeight * 2;
}

// Create the video mesh and add it to the scene
// Create the video mesh and add it to the scene
const videoGeometry = new THREE.PlaneGeometry(1, 1); // Unit size for the geometry
const videoMaterial = new THREE.MeshBasicMaterial({ map: videoTexture, toneMapped: false });
const videoMesh = new THREE.Mesh(videoGeometry, videoMaterial);
videoMesh.position.set(0, 0, 0); // Set position so it's always directly in front of the camera

// Make sure the video mesh is not affected by the camera's position
videoMesh.parent = scene;

// Adjust the video mesh to cover the entire view
resizeVideoMeshToCoverCameraView(camera, videoMesh);

// Position the reflector plane in front of the video mesh



scene.add(videoMesh);




// Update the video mesh size when the window is resized
window.addEventListener('resize', function () {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    resizeVideoMeshToCoverCameraView(camera, videoMesh);
    renderer.setSize(window.innerWidth, window.innerHeight);
});




        // Create orbit controls
        const controls = new THREE.OrbitControls(camera, renderer.domElement);

        // Create an array to store the boxes
      
        // Create an audio context
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();

        // Load your audio file here
        const audioFile = '4.mp3';

        // Create an audio element and connect it to the context
        const audioElement = video;

        const audioSource = audioContext.createMediaElementSource(audioElement);
        audioSource.connect(audioContext.destination);

        // Analyze the audio data
        const analyser = audioContext.createAnalyser();
        audioSource.connect(analyser);

        // Set up the analyser
        analyser.fftSize = 256;
        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);
 const frequencyValue = dataArray[0];

   const reflectiveMaterial = new THREE.MeshStandardMaterial({
  color: 0xffffff, // You can change this color to whatever you prefer
  envMap: videoTexture, // The dynamically updating video texture
  metalness: 0.5, // A value between 0 (non-metallic) and 1 (metallic)
  roughness: 0.2 // A value between 0 (smooth surface) and 1 (rough surface)
});



const visualizerGrid = new AudioVisualizerGrid(scene, analyser, colors, plane);


 


// Start the animation loop


// Handle window resize
window.addEventListener('resize', onWindowResize, false);
function onWindowResize() {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
}        // Create a renderer

function volume() {
 var volume = document.getElementById("volume").value / 100;
var video = document.getElementById('video');

	video.volume = volume;
}

function playPause() {
if (isPlaying == true) {
audioElement.pause();
isPlaying = false;
} else { audioElement.play();
isPlaying = true;
}
}
   function animate() {
 

requestAnimationFrame(animate);
 videoMesh.position.copy(camera.position);
    videoMesh.rotation.copy(camera.rotation);
    videoMesh.translateZ(-camera.far); // Halfway between near and far plane

    if (video.readyState === video.HAVE_ENOUGH_DATA) {
        videoTexture.needsUpdate = true;
    }

            analyser.getByteFrequencyData(dataArray);
            visualizerGrid.updateGrid(dataArray, video.volume);
            renderer.render(scene, camera);
        }

        // Start playing the audio
      audioElement.play();
animate();
document.getElementById('threejs-container').appendChild(renderer.domElement);
       
    </script>

</body>
</html>

